# åç«¯æ¶æ„åˆ†æä¸é›†ç¾¤æ¦‚è§ˆé›†æˆæ–¹æ¡ˆ

> **æ–‡æ¡£ä½œè€…**ï¼šæ¶æ„å¸ˆè§†è§’  
> **æ—¥æœŸ**ï¼š2025-10-24  
> **ç›®æ ‡**ï¼šåˆ†æç°æœ‰æ¶æ„ï¼Œè®¾è®¡é›†ç¾¤æ¦‚è§ˆåŠŸèƒ½çš„æœ€ä½³é›†æˆæ–¹æ¡ˆ

---

## ğŸ“‹ ç›®å½•

- [ä¸€ã€ç°æœ‰æ¶æ„æ·±åº¦åˆ†æ](#ä¸€ç°æœ‰æ¶æ„æ·±åº¦åˆ†æ)
- [äºŒã€æ¶æ„ä¼˜åŠ¿ä¸å¯æ‰©å±•ç‚¹](#äºŒæ¶æ„ä¼˜åŠ¿ä¸å¯æ‰©å±•ç‚¹)
- [ä¸‰ã€é›†æˆæ–¹æ¡ˆè®¾è®¡](#ä¸‰é›†æˆæ–¹æ¡ˆè®¾è®¡)
- [å››ã€å®æ–½è·¯çº¿å›¾](#å››å®æ–½è·¯çº¿å›¾)
- [äº”ã€é£é™©è¯„ä¼°ä¸ç¼“è§£](#äº”é£é™©è¯„ä¼°ä¸ç¼“è§£)

---

## ä¸€ã€ç°æœ‰æ¶æ„æ·±åº¦åˆ†æ

### 1.1 æ•´ä½“æ¶æ„æ¨¡å¼

å½“å‰é‡‡ç”¨**ç»å…¸ä¸‰å±‚æ¶æ„** + **DDDè½»é‡åŒ–**è®¾è®¡ï¼š

```mermaid
graph TB
    subgraph "HTTP Layer"
        Router[Axum Router]
        Middleware[Auth Middleware]
    end
    
    subgraph "Handler Layerï¼ˆè¡¨ç°å±‚ï¼‰"
        AuthHandler[auth.rs]
        ClusterHandler[cluster.rs]
        MonitorHandler[monitor.rs]
        OtherHandlers[...]
    end
    
    subgraph "Service Layerï¼ˆä¸šåŠ¡å±‚ï¼‰"
        AuthService[AuthService]
        ClusterService[ClusterService]
        MySQLPoolMgr[MySQLPoolManager]
        StarRocksClient[StarRocksClient]
        OtherServices[...]
    end
    
    subgraph "Data Layerï¼ˆæ•°æ®å±‚ï¼‰"
        SQLite[(SQLite)]
        StarRocks[(StarRocks Cluster)]
    end
    
    Router --> Middleware
    Middleware --> AuthHandler
    Middleware --> ClusterHandler
    Middleware --> MonitorHandler
    Middleware --> OtherHandlers
    
    AuthHandler --> AuthService
    ClusterHandler --> ClusterService
    MonitorHandler --> ClusterService
    MonitorHandler --> StarRocksClient
    
    AuthService --> SQLite
    ClusterService --> SQLite
    StarRocksClient --> StarRocks
    MySQLPoolMgr --> StarRocks
    
    style Router fill:#e1f5ff
    style Middleware fill:#fff4e1
    style AuthService fill:#e8f5e9
    style ClusterService fill:#e8f5e9
    style SQLite fill:#f3e5f5
    style StarRocks fill:#f3e5f5
```

### 1.2 æ ¸å¿ƒè®¾è®¡æ¨¡å¼

#### 1.2.1 ä¾èµ–æ³¨å…¥ï¼ˆDIï¼‰æ¨¡å¼

```rust
// main.rs - ä¾èµ–æ³¨å…¥å®¹å™¨
pub struct AppState {
    pub db: SqlitePool,                      // æ•°æ®åº“è¿æ¥æ± 
    pub mysql_pool_manager: MySQLPoolManager, // MySQL è¿æ¥æ± ç®¡ç†å™¨
    pub auth_service: AuthService,            // è®¤è¯æœåŠ¡
    pub cluster_service: ClusterService,      // é›†ç¾¤æœåŠ¡
    pub system_function_service: SystemFunctionService,
}
```

**ä¼˜ç‚¹**ï¼š
- âœ… æœåŠ¡è§£è€¦ï¼Œæ˜“äºæµ‹è¯•
- âœ… é€šè¿‡ Arc å®ç°çº¿ç¨‹å®‰å…¨çš„å…±äº«
- âœ… ä¾¿äºæ·»åŠ æ–°æœåŠ¡

**æ‰©å±•ç‚¹**ï¼š
- ğŸ”§ å¯ä»¥æ·»åŠ  `MetricsCollectorService` åˆ° AppState
- ğŸ”§ å¯ä»¥æ·»åŠ  `OverviewService` ä½œä¸ºèšåˆæœåŠ¡

#### 1.2.2 Repository æ¨¡å¼ï¼ˆéšå¼ï¼‰

è™½ç„¶æ²¡æœ‰æ˜¾å¼å®šä¹‰ Repository æ¥å£ï¼Œä½† `ClusterService` å®é™…ä¸Šæ‰¿æ‹…äº† Repository èŒè´£ï¼š

```rust
impl ClusterService {
    // CRUD operations - Repository pattern
    pub async fn create_cluster(&self, ...) -> ApiResult<Cluster>
    pub async fn list_clusters(&self) -> ApiResult<Vec<Cluster>>
    pub async fn get_cluster(&self, cluster_id: i64) -> ApiResult<Cluster>
    pub async fn update_cluster(&self, ...) -> ApiResult<Cluster>
    pub async fn delete_cluster(&self, cluster_id: i64) -> ApiResult<()>
}
```

**ä¼˜ç‚¹**ï¼š
- âœ… æ•°æ®è®¿é—®é€»è¾‘é›†ä¸­
- âœ… æ˜“äºç»´æŠ¤å’Œæµ‹è¯•

**æ”¹è¿›å»ºè®®**ï¼š
- ğŸ’¡ å¯ä»¥å°† Service æ‹†åˆ†ä¸º `ClusterRepository`ï¼ˆæ•°æ®è®¿é—®ï¼‰+ `ClusterService`ï¼ˆä¸šåŠ¡é€»è¾‘ï¼‰
- ğŸ’¡ ä½†å¯¹äºå½“å‰è§„æ¨¡ï¼Œåˆå¹¶è®¾è®¡æ˜¯åˆç†çš„ï¼ˆKISS åŸåˆ™ï¼‰

#### 1.2.3 Client æŠ½è±¡æ¨¡å¼

```rust
pub struct StarRocksClient {
    cluster: Cluster,
}

impl StarRocksClient {
    // å°è£… StarRocks HTTP API è°ƒç”¨
    pub async fn get_metrics(&self) -> ApiResult<String>
    pub async fn get_backends(&self) -> ApiResult<Vec<Backend>>
    pub async fn get_runtime_info(&self) -> ApiResult<RuntimeInfo>
    // ...
}
```

**ä¼˜ç‚¹**ï¼š
- âœ… éš”ç¦»å¤–éƒ¨ä¾èµ–
- âœ… ä¾¿äº Mock æµ‹è¯•
- âœ… æ˜“äºåˆ‡æ¢ä¸åŒçš„é€šä¿¡åè®®

**æ‰©å±•ç‚¹**ï¼š
- ğŸ”§ å¯ä»¥ä¸ºæ–° API æ·»åŠ æ–¹æ³•ï¼ˆå¦‚ `get_databases()`, `get_tables()`, `get_schema_changes()`ï¼‰

#### 1.2.4 çŠ¶æ€ç®¡ç†æ¨¡å¼

è·¯ç”±å±‚ä½¿ç”¨ä¸åŒç²’åº¦çš„ Stateï¼š

```rust
// ä¸åŒçš„ State ç²’åº¦
let cluster_routes = Router::new()
    .route("/api/clusters/:id/metrics/summary", get(handlers::monitor::get_metrics_summary))
    .with_state(cluster_service.clone());  // åªä¾èµ– ClusterService

let app_routes = Router::new()
    .route("/api/clusters/:id/health", get(handlers::cluster::get_cluster_health))
    .with_state(app_state_arc);  // ä¾èµ–å®Œæ•´ AppState
```

**ä¼˜ç‚¹**ï¼š
- âœ… æœ€å°ä¾èµ–åŸåˆ™ï¼ˆPrinciple of Least Privilegeï¼‰
- âœ… é™ä½è€¦åˆåº¦

### 1.3 æ•°æ®æµåˆ†æ

#### 1.3.1 å®æ—¶æ•°æ®æµï¼ˆå½“å‰ï¼‰

```mermaid
sequenceDiagram
    participant Frontend
    participant Handler
    participant Service
    participant StarRocks
    
    Frontend->>Handler: GET /api/clusters/1/metrics/summary
    Handler->>Service: get_cluster(1)
    Service-->>Handler: Cluster
    Handler->>StarRocks: HTTP GET /metrics
    StarRocks-->>Handler: Prometheus Metrics
    Handler->>StarRocks: HTTP GET /api/show_proc?path=/backends
    StarRocks-->>Handler: Backend JSON
    Handler->>StarRocks: HTTP GET /api/show_runtime_info
    StarRocks-->>Handler: Runtime Info
    Handler->>Handler: Aggregate & Calculate
    Handler-->>Frontend: MetricsSummary JSON
```

**ç‰¹ç‚¹**ï¼š
- âš¡ å®æ—¶æ€§å¥½ï¼ˆå»¶è¿Ÿ <100msï¼‰
- âŒ æ— å†å²æ•°æ®
- âŒ æ¯æ¬¡è¯·æ±‚éƒ½éœ€è¦å¤šæ¬¡è°ƒç”¨ StarRocks
- âŒ æ— æ³•å±•ç¤ºè¶‹åŠ¿å›¾

#### 1.3.2 æœŸæœ›æ•°æ®æµï¼ˆé›†ç¾¤æ¦‚è§ˆï¼‰

```mermaid
sequenceDiagram
    participant Frontend
    participant Handler
    participant OverviewService
    participant MetricsCollector
    participant SQLite
    participant StarRocks
    
    Note over MetricsCollector,StarRocks: åå°å®šæ—¶é‡‡é›†ï¼ˆ30sï¼‰
    loop Every 30s
        MetricsCollector->>StarRocks: Collect All Metrics
        StarRocks-->>MetricsCollector: Metrics Data
        MetricsCollector->>SQLite: Store Snapshot
    end
    
    Note over Frontend,OverviewService: ç”¨æˆ·è¯·æ±‚
    Frontend->>Handler: GET /api/clusters/1/overview
    Handler->>OverviewService: get_overview(cluster_id, time_range)
    OverviewService->>SQLite: Query Latest + History
    SQLite-->>OverviewService: Metrics Data
    OverviewService->>OverviewService: Aggregate & Enrich
    OverviewService-->>Handler: ClusterOverview
    Handler-->>Frontend: JSON Response
```

**ä¼˜åŠ¿**ï¼š
- âœ… æ”¯æŒå†å²æ•°æ®å’Œè¶‹åŠ¿åˆ†æ
- âœ… å‡å°‘å¯¹ StarRocks çš„å®æ—¶å‹åŠ›
- âœ… å“åº”é€Ÿåº¦æ›´å¿«ï¼ˆç›´æ¥æŸ¥ SQLiteï¼‰
- âœ… æ•°æ®ä¸€è‡´æ€§æ›´å¥½

### 1.4 ç°æœ‰ç›‘æ§å®ç°åˆ†æ

#### ç›‘æ§ç°çŠ¶

**æ–‡ä»¶**ï¼š`backend/src/handlers/monitor.rs`

```rust
pub async fn get_metrics_summary(
    State(cluster_service): State<ClusterServiceState>,
    Path(cluster_id): Path<i64>,
) -> ApiResult<Json<MetricsSummary>> {
    // 1. è·å–é›†ç¾¤ä¿¡æ¯
    let cluster = cluster_service.get_cluster(cluster_id).await?;
    let client = StarRocksClient::new(cluster);

    // 2. å®æ—¶æ‹‰å–æ•°æ®ï¼ˆæ— ç¼“å­˜ï¼‰
    let metrics_text = client.get_metrics().await?;
    let metrics_map = client.parse_prometheus_metrics(&metrics_text)?;
    let backends = client.get_backends().await?;
    let runtime_info = client.get_runtime_info().await?;

    // 3. èšåˆè®¡ç®—
    // ... æ±‡æ€» backends çš„ CPUã€å†…å­˜ã€ç£ç›˜ç­‰
    
    // 4. è¿”å›å¿«ç…§æ•°æ®
    Ok(Json(summary))
}
```

**é—®é¢˜**ï¼š
1. âŒ **æ— å†å²æ•°æ®**ï¼šåªèƒ½çœ‹åˆ°å½“å‰å¿«ç…§
2. âŒ **é‡å¤è®¡ç®—**ï¼šæ¯æ¬¡è¯·æ±‚éƒ½é‡æ–°èšåˆ
3. âŒ **æ€§èƒ½ç“¶é¢ˆ**ï¼šå¤šä¸ª HTTP è°ƒç”¨ä¸²è¡Œæ‰§è¡Œ
4. âŒ **æ•°æ®å­¤å²›**ï¼š`monitor_history` è¡¨å­˜åœ¨ä½†æœªä½¿ç”¨

**ä¼˜ç‚¹**ï¼š
- âœ… å®æ—¶æ€§å¼º
- âœ… å®ç°ç®€å•

### 1.5 æ•°æ®åº“è®¾è®¡åˆ†æ

#### ç°æœ‰è¡¨ç»“æ„

```sql
-- å·²å­˜åœ¨ä½†æœªå……åˆ†åˆ©ç”¨
CREATE TABLE monitor_history (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    cluster_id INTEGER NOT NULL,
    metric_name VARCHAR(100) NOT NULL,
    metric_value TEXT NOT NULL,  -- âš ï¸ å­˜å‚¨æ ¼å¼ä¸æ˜ç¡®
    collected_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (cluster_id) REFERENCES clusters(id) ON DELETE CASCADE
);

CREATE INDEX idx_monitor_history_cluster_metric ON monitor_history(cluster_id, metric_name);
CREATE INDEX idx_monitor_history_collected_at ON monitor_history(collected_at);
```

**é—®é¢˜**ï¼š
1. âš ï¸ `metric_value TEXT` - ç±»å‹ä¸æ˜ç¡®ï¼Œå¯èƒ½æ˜¯ JSON å­—ç¬¦ä¸²
2. âš ï¸ ç¼ºå°‘ `metric_type` å­—æ®µåŒºåˆ†ä¸åŒç±»å‹çš„æŒ‡æ ‡
3. âš ï¸ æ²¡æœ‰æ•°æ®ä¿ç•™ç­–ç•¥ï¼ˆå¯èƒ½æ— é™å¢é•¿ï¼‰
4. âš ï¸ ç´¢å¼•è®¾è®¡æœªå……åˆ†ä¼˜åŒ–èŒƒå›´æŸ¥è¯¢

**æ”¹è¿›æ–¹æ¡ˆ**ï¼š
- è§"ä¸‰ã€é›†æˆæ–¹æ¡ˆè®¾è®¡"

---

## äºŒã€æ¶æ„ä¼˜åŠ¿ä¸å¯æ‰©å±•ç‚¹

### 2.1 æ¶æ„ä¼˜åŠ¿ï¼ˆä¿æŒå¹¶å‘æ‰¬ï¼‰

#### âœ… 1. æ¸…æ™°çš„åˆ†å±‚æ¶æ„
- **Handler å±‚ä¸“æ³¨äºè¯·æ±‚å“åº”**ï¼šè½»è–„çš„é€‚é…å±‚
- **Service å±‚å°è£…ä¸šåŠ¡é€»è¾‘**ï¼šæ˜“äºå¤ç”¨å’Œæµ‹è¯•
- **Client å±‚éš”ç¦»å¤–éƒ¨ä¾èµ–**ï¼šé™ä½è€¦åˆ

#### âœ… 2. ä¾èµ–æ³¨å…¥è®¾è®¡
- æ‰€æœ‰æœåŠ¡é€šè¿‡ AppState ç»Ÿä¸€ç®¡ç†
- ä½¿ç”¨ Arc å®ç°çº¿ç¨‹å®‰å…¨çš„å…±äº«
- ä¾¿äºæ·»åŠ æ–°æœåŠ¡

#### âœ… 3. ç±»å‹å®‰å…¨
- å¼ºç±»å‹æ¨¡å‹å®šä¹‰ï¼ˆ`models/`ï¼‰
- ç¼–è¯‘æœŸé”™è¯¯æ£€æŸ¥
- Serde è‡ªåŠ¨åºåˆ—åŒ–/ååºåˆ—åŒ–

#### âœ… 4. è‰¯å¥½çš„é”™è¯¯å¤„ç†
- ç»Ÿä¸€çš„ `ApiResult<T>` è¿”å›ç±»å‹
- `ApiError` å°è£…é”™è¯¯ä¿¡æ¯
- ä¾¿äºå‰ç«¯ç»Ÿä¸€å¤„ç†

#### âœ… 5. æ•°æ®åº“è¿ç§»ç®¡ç†
- ä½¿ç”¨ `sqlx::migrate` ç®¡ç† schema å˜æ›´
- ç‰ˆæœ¬åŒ–ç®¡ç†ï¼Œæ˜“äºå›æ»š

### 2.2 å¯æ‰©å±•ç‚¹ï¼ˆæ–°åŠŸèƒ½åµŒå…¥ç‚¹ï¼‰

#### ğŸ”§ æ‰©å±•ç‚¹ 1ï¼šæ·»åŠ æ–°æœåŠ¡

```rust
// âœ… å¯ä»¥æ— ç¼æ·»åŠ æ–°æœåŠ¡åˆ° AppState
pub struct AppState {
    pub db: SqlitePool,
    pub mysql_pool_manager: MySQLPoolManager,
    pub auth_service: AuthService,
    pub cluster_service: ClusterService,
    pub system_function_service: SystemFunctionService,
    // ğŸ†• æ–°å¢
    pub metrics_collector_service: MetricsCollectorService,  // æŒ‡æ ‡é‡‡é›†æœåŠ¡
    pub overview_service: OverviewService,                   // æ¦‚è§ˆèšåˆæœåŠ¡
}
```

#### ğŸ”§ æ‰©å±•ç‚¹ 2ï¼šæ·»åŠ æ–°çš„ Handler

```rust
// handlers/overview.rs - æ–°å¢ handler æ¨¡å—
pub async fn get_cluster_overview(
    State(overview_service): State<Arc<OverviewService>>,
    Path(cluster_id): Path<i64>,
    Query(params): Query<OverviewQueryParams>,
) -> ApiResult<Json<ClusterOverview>> {
    // ... å®ç°
}
```

#### ğŸ”§ æ‰©å±•ç‚¹ 3ï¼šæ‰©å±• StarRocksClient

```rust
impl StarRocksClient {
    // âœ… æ·»åŠ æ–°çš„ API æ–¹æ³•
    pub async fn get_databases(&self) -> ApiResult<Vec<Database>> { /* ... */ }
    pub async fn get_tables(&self, db: &str) -> ApiResult<Vec<Table>> { /* ... */ }
    pub async fn get_table_info(&self, db: &str, table: &str) -> ApiResult<TableInfo> { /* ... */ }
    pub async fn get_schema_changes(&self) -> ApiResult<Vec<SchemaChange>> { /* ... */ }
}
```

#### ğŸ”§ æ‰©å±•ç‚¹ 4ï¼šæ•°æ®åº“ Schema æ‰©å±•

```sql
-- migrations/20250124_add_cluster_overview.sql
-- âœ… é€šè¿‡æ–°çš„ migration æ–‡ä»¶æ·»åŠ è¡¨

CREATE TABLE metrics_snapshots (...);
CREATE TABLE daily_snapshots (...);
```

#### ğŸ”§ æ‰©å±•ç‚¹ 5ï¼šåå°ä»»åŠ¡

```rust
// âœ… åœ¨ main.rs ä¸­å¯åŠ¨åå°ä»»åŠ¡
#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // ... ç°æœ‰åˆå§‹åŒ– ...
    
    // ğŸ†• å¯åŠ¨æŒ‡æ ‡é‡‡é›†å™¨
    let collector = MetricsCollectorService::new(/* ... */);
    tokio::spawn(async move {
        collector.start_collection().await;
    });
    
    // ... å¯åŠ¨ HTTP æœåŠ¡ ...
}
```

---

## ä¸‰ã€é›†æˆæ–¹æ¡ˆè®¾è®¡

### 3.1 æ¶æ„é›†æˆåŸåˆ™

#### åŸåˆ™ 1ï¸âƒ£ï¼šæœ€å°ä¾µå…¥æ€§ï¼ˆMinimal Invasionï¼‰
- âœ… ä¸ä¿®æ”¹ç°æœ‰ä»£ç çš„æ ¸å¿ƒé€»è¾‘
- âœ… é€šè¿‡æ‰©å±•è€Œéä¿®æ”¹ï¼ˆOpen-Closed Principleï¼‰
- âœ… ç°æœ‰ API ä¿æŒå‘åå…¼å®¹

#### åŸåˆ™ 2ï¸âƒ£ï¼šå•ä¸€èŒè´£ï¼ˆSingle Responsibilityï¼‰
- âœ… æ¯ä¸ªæœåŠ¡åªè´Ÿè´£ä¸€ä»¶äº‹
- âœ… é‡‡é›†ã€å­˜å‚¨ã€æŸ¥è¯¢ã€èšåˆåˆ†ç¦»

#### åŸåˆ™ 3ï¸âƒ£ï¼šä¾èµ–å€’ç½®ï¼ˆDependency Inversionï¼‰
- âœ… é«˜å±‚æ¨¡å—ä¸ä¾èµ–ä½å±‚æ¨¡å—
- âœ… é€šè¿‡æ¥å£/trait è§£è€¦

#### åŸåˆ™ 4ï¸âƒ£ï¼šå¯æµ‹è¯•æ€§ï¼ˆTestabilityï¼‰
- âœ… æ‰€æœ‰æœåŠ¡å¯ç‹¬ç«‹æµ‹è¯•
- âœ… æ”¯æŒ Mock å¤–éƒ¨ä¾èµ–

### 3.2 æ–°å¢ç»„ä»¶è®¾è®¡

#### 3.2.1 æœåŠ¡å±‚æ¶æ„

```mermaid
graph TB
    subgraph "æ–°å¢æœåŠ¡ï¼ˆNew Servicesï¼‰"
        MetricsCollector[MetricsCollectorService<br/>æŒ‡æ ‡é‡‡é›†æœåŠ¡]
        OverviewService[OverviewService<br/>æ¦‚è§ˆèšåˆæœåŠ¡]
        MetricsRepo[MetricsRepository<br/>æŒ‡æ ‡æ•°æ®è®¿é—®å±‚]
    end
    
    subgraph "ç°æœ‰æœåŠ¡ï¼ˆExisting Servicesï¼‰"
        ClusterService[ClusterService]
        StarRocksClient[StarRocksClient]
    end
    
    subgraph "æ•°æ®å±‚ï¼ˆData Layerï¼‰"
        SQLite[(SQLite)]
        StarRocks[(StarRocks)]
    end
    
    MetricsCollector --> ClusterService
    MetricsCollector --> StarRocksClient
    MetricsCollector --> MetricsRepo
    
    OverviewService --> MetricsRepo
    OverviewService --> ClusterService
    
    MetricsRepo --> SQLite
    ClusterService --> SQLite
    StarRocksClient --> StarRocks
    
    style MetricsCollector fill:#c8e6c9
    style OverviewService fill:#c8e6c9
    style MetricsRepo fill:#c8e6c9
    style ClusterService fill:#e3f2fd
    style StarRocksClient fill:#e3f2fd
```

#### 3.2.2 MetricsCollectorServiceï¼ˆæ ¸å¿ƒæ–°å¢ï¼‰

**èŒè´£**ï¼š
- ğŸ“Š å®šæ—¶é‡‡é›†æ‰€æœ‰é›†ç¾¤çš„æŒ‡æ ‡
- ğŸ’¾ å­˜å‚¨åˆ° SQLite
- ğŸ—‘ï¸ è‡ªåŠ¨æ¸…ç†è¿‡æœŸæ•°æ®

**è®¾è®¡**ï¼š

```rust
// services/metrics_collector_service.rs

use std::sync::Arc;
use tokio::time::{interval, Duration};
use sqlx::SqlitePool;
use crate::services::{ClusterService, StarRocksClient};

pub struct MetricsCollectorService {
    db: SqlitePool,
    cluster_service: Arc<ClusterService>,
    collection_interval: Duration,  // 30 ç§’
    retention_days: i64,             // 7 å¤©
}

impl MetricsCollectorService {
    pub fn new(
        db: SqlitePool,
        cluster_service: Arc<ClusterService>,
    ) -> Self {
        Self {
            db,
            cluster_service,
            collection_interval: Duration::from_secs(30),
            retention_days: 7,
        }
    }

    // å¯åŠ¨å®šæ—¶é‡‡é›†ï¼ˆåœ¨ main.rs ä¸­è°ƒç”¨ï¼‰
    pub async fn start_collection(self: Arc<Self>) {
        let mut ticker = interval(self.collection_interval);
        
        loop {
            ticker.tick().await;
            
            if let Err(e) = self.collect_all_clusters().await {
                tracing::error!("Failed to collect metrics: {}", e);
            }
        }
    }

    // é‡‡é›†æ‰€æœ‰é›†ç¾¤çš„æŒ‡æ ‡
    async fn collect_all_clusters(&self) -> Result<(), anyhow::Error> {
        let clusters = self.cluster_service.list_clusters().await?;
        
        for cluster in clusters {
            if let Err(e) = self.collect_cluster_metrics(&cluster).await {
                tracing::error!("Failed to collect metrics for cluster {}: {}", 
                               cluster.id, e);
                // ç»§ç»­é‡‡é›†å…¶ä»–é›†ç¾¤
            }
        }
        
        // æ¸…ç†è¿‡æœŸæ•°æ®
        self.cleanup_old_metrics().await?;
        
        Ok(())
    }

    // é‡‡é›†å•ä¸ªé›†ç¾¤çš„æŒ‡æ ‡
    async fn collect_cluster_metrics(&self, cluster: &Cluster) -> Result<(), anyhow::Error> {
        let client = StarRocksClient::new(cluster.clone());
        
        // 1. é‡‡é›† Prometheus æŒ‡æ ‡
        let metrics_text = client.get_metrics().await?;
        let metrics_map = client.parse_prometheus_metrics(&metrics_text)?;
        
        // 2. é‡‡é›† Backends ä¿¡æ¯
        let backends = client.get_backends().await?;
        
        // 3. é‡‡é›† Runtime ä¿¡æ¯
        let runtime_info = client.get_runtime_info().await?;
        
        // 4. é‡‡é›†æ•°æ®åº“/è¡¨ä¿¡æ¯ï¼ˆæ–°å¢ï¼‰
        let databases = client.get_databases().await?;
        
        // 5. é‡‡é›†ç‰©åŒ–è§†å›¾ä¿¡æ¯ï¼ˆå¯é€‰ï¼Œå¦‚æœæœ‰ APIï¼‰
        // let mvs = client.get_materialized_views().await?;
        
        // 6. èšåˆå¹¶å­˜å‚¨
        let snapshot = MetricsSnapshot {
            cluster_id: cluster.id,
            collected_at: Utc::now(),
            // Query metrics
            qps: metrics_map.get("starrocks_fe_qps").copied().unwrap_or(0.0),
            rps: metrics_map.get("starrocks_fe_rps").copied().unwrap_or(0.0),
            query_latency_p99: metrics_map.get("starrocks_fe_query_latency_p99").copied().unwrap_or(0.0),
            // ... å…¶ä»–æŒ‡æ ‡
            
            // Aggregated metrics
            backend_total: backends.len() as i32,
            backend_alive: backends.iter().filter(|b| b.alive == "true").count() as i32,
            total_cpu_usage: backends.iter()
                .filter_map(|b| b.cpu_used_pct.trim_end_matches('%').parse::<f64>().ok())
                .sum(),
            // ... æ›´å¤šèšåˆæŒ‡æ ‡
        };
        
        // ä¿å­˜åˆ°æ•°æ®åº“
        self.save_snapshot(&snapshot).await?;
        
        Ok(())
    }

    // ä¿å­˜å¿«ç…§åˆ°æ•°æ®åº“
    async fn save_snapshot(&self, snapshot: &MetricsSnapshot) -> Result<(), sqlx::Error> {
        sqlx::query!(
            r#"
            INSERT INTO metrics_snapshots (
                cluster_id, collected_at, snapshot_data
            ) VALUES (?, ?, ?)
            "#,
            snapshot.cluster_id,
            snapshot.collected_at,
            serde_json::to_string(snapshot).unwrap()
        )
        .execute(&self.db)
        .await?;
        
        Ok(())
    }

    // æ¸…ç†è¿‡æœŸæ•°æ®
    async fn cleanup_old_metrics(&self) -> Result<(), sqlx::Error> {
        let cutoff_date = Utc::now() - chrono::Duration::days(self.retention_days);
        
        sqlx::query!(
            "DELETE FROM metrics_snapshots WHERE collected_at < ?",
            cutoff_date
        )
        .execute(&self.db)
        .await?;
        
        tracing::info!("Cleaned up metrics older than {} days", self.retention_days);
        
        Ok(())
    }
}
```

#### 3.2.3 OverviewServiceï¼ˆèšåˆæœåŠ¡ï¼‰

**èŒè´£**ï¼š
- ğŸ“ˆ æä¾›é›†ç¾¤æ¦‚è§ˆæ•°æ®ï¼ˆå®æ—¶ + å†å²ï¼‰
- ğŸ”„ èšåˆå¤šç§æ•°æ®æº
- ğŸ¯ æŒ‰æ—¶é—´èŒƒå›´æŸ¥è¯¢å†å²è¶‹åŠ¿

**è®¾è®¡**ï¼š

```rust
// services/overview_service.rs

pub struct OverviewService {
    db: SqlitePool,
    cluster_service: Arc<ClusterService>,
}

impl OverviewService {
    pub fn new(db: SqlitePool, cluster_service: Arc<ClusterService>) -> Self {
        Self { db, cluster_service }
    }

    // è·å–é›†ç¾¤æ¦‚è§ˆï¼ˆæ ¸å¿ƒ APIï¼‰
    pub async fn get_cluster_overview(
        &self,
        cluster_id: i64,
        time_range: TimeRange,
    ) -> ApiResult<ClusterOverview> {
        // 1. è·å–æœ€æ–°å¿«ç…§ï¼ˆå®æ—¶æ•°æ®ï¼‰
        let latest = self.get_latest_snapshot(cluster_id).await?;
        
        // 2. è·å–å†å²è¶‹åŠ¿æ•°æ®
        let history = self.get_history_snapshots(cluster_id, time_range).await?;
        
        // 3. è®¡ç®—èšåˆæŒ‡æ ‡
        let aggregated = self.aggregate_metrics(&latest, &history).await?;
        
        // 4. ç»„è£…å®Œæ•´æ¦‚è§ˆ
        Ok(ClusterOverview {
            cluster_id,
            timestamp: Utc::now(),
            real_time: latest,
            trends: history,
            aggregated,
        })
    }

    // è·å–å¥åº·çŠ¶æ€å¡ç‰‡
    pub async fn get_health_cards(
        &self,
        cluster_id: i64,
    ) -> ApiResult<Vec<HealthCard>> {
        let snapshot = self.get_latest_snapshot(cluster_id).await?;
        
        Ok(vec![
            HealthCard {
                title: "é›†ç¾¤çŠ¶æ€".to_string(),
                value: snapshot.cluster_status.clone(),
                status: self.determine_health_status(&snapshot),
                // ...
            },
            // ... æ›´å¤šå¡ç‰‡
        ])
    }

    // è·å–æ€§èƒ½è¶‹åŠ¿
    pub async fn get_performance_trends(
        &self,
        cluster_id: i64,
        time_range: TimeRange,
    ) -> ApiResult<PerformanceTrends> {
        let snapshots = self.get_history_snapshots(cluster_id, time_range).await?;
        
        Ok(PerformanceTrends {
            qps: snapshots.iter().map(|s| (s.collected_at, s.qps)).collect(),
            latency_p99: snapshots.iter().map(|s| (s.collected_at, s.query_latency_p99)).collect(),
            // ...
        })
    }

    // å†…éƒ¨æ–¹æ³•ï¼šè·å–æœ€æ–°å¿«ç…§
    async fn get_latest_snapshot(&self, cluster_id: i64) -> ApiResult<MetricsSnapshot> {
        sqlx::query_as!(
            MetricsSnapshot,
            r#"
            SELECT * FROM metrics_snapshots
            WHERE cluster_id = ?
            ORDER BY collected_at DESC
            LIMIT 1
            "#,
            cluster_id
        )
        .fetch_one(&self.db)
        .await
        .map_err(|_| ApiError::new(ErrorCode::NotFound, "No metrics found"))
    }

    // å†…éƒ¨æ–¹æ³•ï¼šè·å–å†å²å¿«ç…§
    async fn get_history_snapshots(
        &self,
        cluster_id: i64,
        time_range: TimeRange,
    ) -> ApiResult<Vec<MetricsSnapshot>> {
        let start_time = time_range.start();
        let end_time = time_range.end();
        
        sqlx::query_as!(
            MetricsSnapshot,
            r#"
            SELECT * FROM metrics_snapshots
            WHERE cluster_id = ? 
              AND collected_at BETWEEN ? AND ?
            ORDER BY collected_at ASC
            "#,
            cluster_id,
            start_time,
            end_time
        )
        .fetch_all(&self.db)
        .await
        .map_err(Into::into)
    }
}
```

#### 3.2.4 æ‰©å±• StarRocksClient

**æ–°å¢æ–¹æ³•**ï¼š

```rust
// services/starrocks_client.rs

impl StarRocksClient {
    // ğŸ†• è·å–æ•°æ®åº“åˆ—è¡¨
    pub async fn get_databases(&self) -> ApiResult<Vec<Database>> {
        let url = format!(
            "{}://{}/api/v1/catalogs/{}/databases",
            self.scheme(),
            self.cluster.fe_host,
            self.cluster.catalog
        );
        
        let response = self.client
            .get(&url)
            .basic_auth(&self.cluster.username, Some(&self.cluster.password_encrypted))
            .send()
            .await?;
        
        self.handle_response(response).await
    }

    // ğŸ†• è·å–è¡¨åˆ—è¡¨
    pub async fn get_tables(&self, database: &str) -> ApiResult<Vec<Table>> {
        let url = format!(
            "{}://{}/api/v1/catalogs/{}/databases/{}/tables",
            self.scheme(),
            self.cluster.fe_host,
            self.cluster.catalog,
            database
        );
        
        let response = self.client
            .get(&url)
            .basic_auth(&self.cluster.username, Some(&self.cluster.password_encrypted))
            .send()
            .await?;
        
        self.handle_response(response).await
    }

    // ğŸ†• è·å–è¡¨è¯¦æƒ…ï¼ˆåŒ…å«å¤§å°ã€è¡Œæ•°ç­‰ï¼‰
    pub async fn get_table_info(&self, database: &str, table: &str) -> ApiResult<TableInfo> {
        // æ–¹å¼1ï¼šé€šè¿‡ HTTP APIï¼ˆå¦‚æœæ”¯æŒï¼‰
        // æ–¹å¼2ï¼šé€šè¿‡ MySQL åè®®æŸ¥è¯¢ information_schema
        // è¿™é‡Œéœ€è¦ç»“åˆ MySQLClient
        todo!()
    }

    // ğŸ†• è·å– Schema Change ä»»åŠ¡
    pub async fn get_schema_changes(&self) -> ApiResult<Vec<SchemaChange>> {
        let url = format!(
            "{}://{}/api/show_proc?path=/jobs",
            self.scheme(),
            self.cluster.fe_host
        );
        
        let response = self.client
            .get(&url)
            .basic_auth(&self.cluster.username, Some(&self.cluster.password_encrypted))
            .send()
            .await?;
        
        self.handle_response(response).await
    }

    // ğŸ†• è·å–æ´»è·ƒç”¨æˆ·æ•°ï¼ˆé€šè¿‡ SHOW PROCESSLISTï¼‰
    pub async fn get_active_users(&self) -> ApiResult<Vec<String>> {
        let url = format!(
            "{}://{}/api/show_proc?path=/current_queries",
            self.scheme(),
            self.cluster.fe_host
        );
        
        let response = self.client
            .get(&url)
            .basic_auth(&self.cluster.username, Some(&self.cluster.password_encrypted))
            .send()
            .await?;
        
        let queries: Vec<Query> = self.handle_response(response).await?;
        
        // æå–å”¯ä¸€ç”¨æˆ·
        let unique_users: std::collections::HashSet<String> = queries
            .iter()
            .map(|q| q.user.clone())
            .collect();
        
        Ok(unique_users.into_iter().collect())
    }
}
```

### 3.3 æ•°æ®åº“ Schema è®¾è®¡

#### 3.3.1 ä¼˜åŒ–ç°æœ‰è¡¨

ä¿æŒ `monitor_history` è¡¨ä¸å˜ï¼ˆå‘åå…¼å®¹ï¼‰ï¼Œæ–°å¢ä¸“ç”¨è¡¨ï¼š

```sql
-- migrations/20250124_add_cluster_overview.sql

-- ========================================
-- 1. æŒ‡æ ‡å¿«ç…§è¡¨ï¼ˆé«˜é¢‘é‡‡é›†ï¼Œ30ç§’ä¸€æ¬¡ï¼‰
-- ========================================
CREATE TABLE IF NOT EXISTS metrics_snapshots (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    cluster_id INTEGER NOT NULL,
    collected_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    
    -- æŸ¥è¯¢æ€§èƒ½æŒ‡æ ‡
    qps REAL NOT NULL DEFAULT 0.0,
    rps REAL NOT NULL DEFAULT 0.0,
    query_latency_p50 REAL NOT NULL DEFAULT 0.0,
    query_latency_p95 REAL NOT NULL DEFAULT 0.0,
    query_latency_p99 REAL NOT NULL DEFAULT 0.0,
    query_total BIGINT NOT NULL DEFAULT 0,
    query_success BIGINT NOT NULL DEFAULT 0,
    query_error BIGINT NOT NULL DEFAULT 0,
    query_timeout BIGINT NOT NULL DEFAULT 0,
    
    -- é›†ç¾¤å¥åº·æŒ‡æ ‡
    backend_total INTEGER NOT NULL DEFAULT 0,
    backend_alive INTEGER NOT NULL DEFAULT 0,
    frontend_total INTEGER NOT NULL DEFAULT 0,
    frontend_alive INTEGER NOT NULL DEFAULT 0,
    
    -- èµ„æºä½¿ç”¨æŒ‡æ ‡
    total_cpu_usage REAL NOT NULL DEFAULT 0.0,
    avg_cpu_usage REAL NOT NULL DEFAULT 0.0,
    total_memory_usage REAL NOT NULL DEFAULT 0.0,
    avg_memory_usage REAL NOT NULL DEFAULT 0.0,
    disk_total_bytes BIGINT NOT NULL DEFAULT 0,
    disk_used_bytes BIGINT NOT NULL DEFAULT 0,
    disk_usage_pct REAL NOT NULL DEFAULT 0.0,
    
    -- å­˜å‚¨æŒ‡æ ‡
    tablet_count BIGINT NOT NULL DEFAULT 0,
    max_compaction_score REAL NOT NULL DEFAULT 0.0,
    
    -- äº‹åŠ¡æŒ‡æ ‡
    txn_running INTEGER NOT NULL DEFAULT 0,
    txn_success_total BIGINT NOT NULL DEFAULT 0,
    txn_failed_total BIGINT NOT NULL DEFAULT 0,
    
    -- è´Ÿè½½æŒ‡æ ‡
    load_running INTEGER NOT NULL DEFAULT 0,
    load_finished_total BIGINT NOT NULL DEFAULT 0,
    
    -- åŸå§‹æ•°æ®ï¼ˆJSON æ ¼å¼ï¼Œç”¨äºçµæ´»æ‰©å±•ï¼‰
    raw_metrics TEXT,
    
    FOREIGN KEY (cluster_id) REFERENCES clusters(id) ON DELETE CASCADE
);

-- ç´¢å¼•ä¼˜åŒ–
CREATE INDEX IF NOT EXISTS idx_metrics_snapshots_cluster_time 
ON metrics_snapshots(cluster_id, collected_at DESC);

CREATE INDEX IF NOT EXISTS idx_metrics_snapshots_time 
ON metrics_snapshots(collected_at DESC);

-- ========================================
-- 2. æ¯æ—¥æ±‡æ€»è¡¨ï¼ˆä½é¢‘å­˜å‚¨ï¼Œ1å¤©1æ¬¡ï¼‰
-- ========================================
CREATE TABLE IF NOT EXISTS daily_snapshots (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    cluster_id INTEGER NOT NULL,
    snapshot_date DATE NOT NULL,
    
    -- èšåˆç»Ÿè®¡
    avg_qps REAL NOT NULL DEFAULT 0.0,
    max_qps REAL NOT NULL DEFAULT 0.0,
    avg_latency_p99 REAL NOT NULL DEFAULT 0.0,
    total_queries BIGINT NOT NULL DEFAULT 0,
    total_errors BIGINT NOT NULL DEFAULT 0,
    
    -- å®¹é‡ç»Ÿè®¡
    avg_disk_usage_pct REAL NOT NULL DEFAULT 0.0,
    max_disk_usage_pct REAL NOT NULL DEFAULT 0.0,
    
    -- å¯ç”¨æ€§ç»Ÿè®¡
    avg_backend_alive REAL NOT NULL DEFAULT 0.0,
    total_downtime_seconds INTEGER NOT NULL DEFAULT 0,
    
    FOREIGN KEY (cluster_id) REFERENCES clusters(id) ON DELETE CASCADE,
    UNIQUE(cluster_id, snapshot_date)
);

CREATE INDEX IF NOT EXISTS idx_daily_snapshots_cluster_date 
ON daily_snapshots(cluster_id, snapshot_date DESC);

-- ========================================
-- 3. æ•°æ®æ¦‚å†µç¼“å­˜è¡¨ï¼ˆæŒ‰éœ€æ›´æ–°ï¼‰
-- ========================================
CREATE TABLE IF NOT EXISTS data_statistics (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    cluster_id INTEGER NOT NULL,
    updated_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    
    -- æ•°æ®åº“/è¡¨ç»Ÿè®¡
    database_count INTEGER NOT NULL DEFAULT 0,
    table_count INTEGER NOT NULL DEFAULT 0,
    total_data_size BIGINT NOT NULL DEFAULT 0,
    
    -- Top è¡¨ï¼ˆJSON æ•°ç»„ï¼‰
    top_tables_by_size TEXT,  -- JSON: [{table, size}, ...]
    top_tables_by_access TEXT,  -- JSON: [{table, access_count}, ...]
    
    -- ç‰©åŒ–è§†å›¾ç»Ÿè®¡
    mv_total INTEGER NOT NULL DEFAULT 0,
    mv_running INTEGER NOT NULL DEFAULT 0,
    mv_failed INTEGER NOT NULL DEFAULT 0,
    
    -- Schema å˜æ›´ç»Ÿè®¡
    schema_change_running INTEGER NOT NULL DEFAULT 0,
    schema_change_pending INTEGER NOT NULL DEFAULT 0,
    
    FOREIGN KEY (cluster_id) REFERENCES clusters(id) ON DELETE CASCADE,
    UNIQUE(cluster_id)
);

CREATE INDEX IF NOT EXISTS idx_data_statistics_cluster 
ON data_statistics(cluster_id);
```

#### 3.3.2 æ•°æ®ä¿ç•™ç­–ç•¥

```rust
// åœ¨ MetricsCollectorService ä¸­å®ç°

impl MetricsCollectorService {
    async fn apply_retention_policy(&self) -> Result<(), sqlx::Error> {
        // 1. metrics_snapshots: ä¿ç•™ 7 å¤©
        let cutoff_7d = Utc::now() - chrono::Duration::days(7);
        sqlx::query!("DELETE FROM metrics_snapshots WHERE collected_at < ?", cutoff_7d)
            .execute(&self.db).await?;
        
        // 2. daily_snapshots: ä¿ç•™ 90 å¤©
        let cutoff_90d = Utc::now() - chrono::Duration::days(90);
        sqlx::query!("DELETE FROM daily_snapshots WHERE snapshot_date < ?", cutoff_90d)
            .execute(&self.db).await?;
        
        // 3. æ‰§è¡Œ VACUUM å‹ç¼©æ•°æ®åº“
        sqlx::query("VACUUM").execute(&self.db).await?;
        
        Ok(())
    }
}
```

### 3.4 API è®¾è®¡

#### 3.4.1 æ–°å¢ API ç«¯ç‚¹

```rust
// handlers/overview.rs

// ğŸ†• è·å–é›†ç¾¤æ¦‚è§ˆ
#[utoipa::path(
    get,
    path = "/api/clusters/{id}/overview",
    params(
        ("id" = i64, Path, description = "Cluster ID"),
        ("time_range" = Option<String>, Query, description = "Time range: 1h, 6h, 24h, 3d")
    ),
    responses(
        (status = 200, description = "Cluster overview", body = ClusterOverview),
        (status = 404, description = "Cluster not found")
    ),
    tag = "Cluster Overview"
)]
pub async fn get_cluster_overview(
    State(overview_service): State<Arc<OverviewService>>,
    Path(cluster_id): Path<i64>,
    Query(params): Query<OverviewQueryParams>,
) -> ApiResult<Json<ClusterOverview>> {
    let time_range = params.time_range.unwrap_or_else(|| TimeRange::Hours(24));
    let overview = overview_service.get_cluster_overview(cluster_id, time_range).await?;
    Ok(Json(overview))
}

// ğŸ†• è·å–å¥åº·çŠ¶æ€å¡ç‰‡
#[utoipa::path(
    get,
    path = "/api/clusters/{id}/overview/health",
    tag = "Cluster Overview"
)]
pub async fn get_health_cards(
    State(overview_service): State<Arc<OverviewService>>,
    Path(cluster_id): Path<i64>,
) -> ApiResult<Json<Vec<HealthCard>>> {
    let cards = overview_service.get_health_cards(cluster_id).await?;
    Ok(Json(cards))
}

// ğŸ†• è·å–æ€§èƒ½è¶‹åŠ¿
#[utoipa::path(
    get,
    path = "/api/clusters/{id}/overview/performance",
    tag = "Cluster Overview"
)]
pub async fn get_performance_trends(
    State(overview_service): State<Arc<OverviewService>>,
    Path(cluster_id): Path<i64>,
    Query(params): Query<TrendQueryParams>,
) -> ApiResult<Json<PerformanceTrends>> {
    let trends = overview_service.get_performance_trends(cluster_id, params.time_range).await?;
    Ok(Json(trends))
}

// ğŸ†• è·å–èµ„æºä½¿ç”¨è¶‹åŠ¿
#[utoipa::path(
    get,
    path = "/api/clusters/{id}/overview/resources",
    tag = "Cluster Overview"
)]
pub async fn get_resource_trends(
    State(overview_service): State<Arc<OverviewService>>,
    Path(cluster_id): Path<i64>,
    Query(params): Query<TrendQueryParams>,
) -> ApiResult<Json<ResourceTrends>> {
    let trends = overview_service.get_resource_trends(cluster_id, params.time_range).await?;
    Ok(Json(trends))
}

// ğŸ†• è·å–æ•°æ®ç»Ÿè®¡
#[utoipa::path(
    get,
    path = "/api/clusters/{id}/overview/data-stats",
    tag = "Cluster Overview"
)]
pub async fn get_data_statistics(
    State(overview_service): State<Arc<OverviewService>>,
    Path(cluster_id): Path<i64>,
) -> ApiResult<Json<DataStatistics>> {
    let stats = overview_service.get_data_statistics(cluster_id).await?;
    Ok(Json(stats))
}
```

#### 3.4.2 è·¯ç”±æ³¨å†Œ

```rust
// main.rs - æ·»åŠ åˆ°è·¯ç”±é…ç½®

let overview_routes = Router::new()
    .route("/api/clusters/:id/overview", get(handlers::overview::get_cluster_overview))
    .route("/api/clusters/:id/overview/health", get(handlers::overview::get_health_cards))
    .route("/api/clusters/:id/overview/performance", get(handlers::overview::get_performance_trends))
    .route("/api/clusters/:id/overview/resources", get(handlers::overview::get_resource_trends))
    .route("/api/clusters/:id/overview/data-stats", get(handlers::overview::get_data_statistics))
    .with_state(app_state.overview_service.clone());

// åˆå¹¶åˆ° protected_routes
let protected_routes = Router::new()
    .merge(auth_routes)
    .merge(cluster_routes)
    .merge(app_routes)
    .merge(overview_routes)  // ğŸ†• æ·»åŠ æ¦‚è§ˆè·¯ç”±
    .layer(axum_middleware::from_fn_with_state(
        auth_state,
        middleware::auth_middleware,
    ));
```

### 3.5 å¯åŠ¨æµç¨‹é›†æˆ

#### ä¿®æ”¹ main.rs

```rust
// main.rs

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // ... ç°æœ‰åˆå§‹åŒ–ä»£ç  ...
    
    // ğŸ†• åˆ›å»ºæ–°æœåŠ¡
    let metrics_collector_service = Arc::new(MetricsCollectorService::new(
        pool.clone(),
        cluster_service.clone(),
    ));
    
    let overview_service = Arc::new(OverviewService::new(
        pool.clone(),
        cluster_service.clone(),
    ));

    // ğŸ†• æ›´æ–° AppState
    let app_state = AppState {
        db: pool.clone(),
        mysql_pool_manager: (*mysql_pool_manager).clone(),
        auth_service: (*auth_service).clone(),
        cluster_service: (*cluster_service).clone(),
        system_function_service: (*system_function_service).clone(),
        // æ–°å¢
        metrics_collector_service: (*metrics_collector_service).clone(),
        overview_service: (*overview_service).clone(),
    };

    // ... è·¯ç”±é…ç½® ...

    // ğŸ†• å¯åŠ¨åå°ä»»åŠ¡
    let collector_clone = metrics_collector_service.clone();
    tokio::spawn(async move {
        tracing::info!("Starting metrics collector background task");
        collector_clone.start_collection().await;
    });

    // ... å¯åŠ¨ HTTP æœåŠ¡ ...
}
```

---

## å››ã€å®æ–½è·¯çº¿å›¾

### Phase 1ï¼šåŸºç¡€æ¶æ„æ­å»ºï¼ˆP0ï¼‰

**ç›®æ ‡**ï¼šå»ºç«‹æ ¸å¿ƒé‡‡é›†å’Œå­˜å‚¨èƒ½åŠ›

#### ä»»åŠ¡æ¸…å•

- [ ] **Task 1.1**ï¼šæ•°æ®åº“ Schema è®¾è®¡ä¸è¿ç§»
  - åˆ›å»º `metrics_snapshots` è¡¨
  - åˆ›å»º `daily_snapshots` è¡¨
  - åˆ›å»º `data_statistics` è¡¨
  - ç¼–å†™è¿ç§»æ–‡ä»¶
  - **é¢„ä¼°**ï¼š4 å°æ—¶

- [ ] **Task 1.2**ï¼šæ‰©å±• StarRocksClient
  - æ·»åŠ  `get_databases()` æ–¹æ³•
  - æ·»åŠ  `get_tables()` æ–¹æ³•
  - æ·»åŠ  `get_schema_changes()` æ–¹æ³•
  - æ·»åŠ  `get_active_users()` æ–¹æ³•
  - **é¢„ä¼°**ï¼š6 å°æ—¶

- [ ] **Task 1.3**ï¼šå®ç° MetricsCollectorService
  - æ ¸å¿ƒé‡‡é›†é€»è¾‘
  - æ•°æ®èšåˆè®¡ç®—
  - æ•°æ®æŒä¹…åŒ–
  - é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
  - **é¢„ä¼°**ï¼š10 å°æ—¶

- [ ] **Task 1.4**ï¼šå®ç° OverviewService
  - `get_cluster_overview()` æ ¸å¿ƒæ–¹æ³•
  - `get_latest_snapshot()` æŸ¥è¯¢æ–¹æ³•
  - `get_history_snapshots()` æŸ¥è¯¢æ–¹æ³•
  - æ•°æ®èšåˆé€»è¾‘
  - **é¢„ä¼°**ï¼š8 å°æ—¶

- [ ] **Task 1.5**ï¼šé›†æˆåˆ° main.rs
  - æ›´æ–° AppState ç»“æ„
  - å¯åŠ¨åå°é‡‡é›†ä»»åŠ¡
  - é…ç½®è·¯ç”±
  - **é¢„ä¼°**ï¼š2 å°æ—¶

**Total Phase 1**ï¼š30 å°æ—¶ â†’ **çº¦ 4 å¤©**

---

### Phase 2ï¼šAPI å¼€å‘ï¼ˆP0ï¼‰

**ç›®æ ‡**ï¼šæä¾›å®Œæ•´çš„ API æ¥å£

#### ä»»åŠ¡æ¸…å•

- [ ] **Task 2.1**ï¼šå®šä¹‰æ•°æ®æ¨¡å‹
  - `ClusterOverview` struct
  - `HealthCard` struct
  - `PerformanceTrends` struct
  - `ResourceTrends` struct
  - `DataStatistics` struct
  - **é¢„ä¼°**ï¼š3 å°æ—¶

- [ ] **Task 2.2**ï¼šå®ç° overview handler
  - `get_cluster_overview()` handler
  - `get_health_cards()` handler
  - `get_performance_trends()` handler
  - `get_resource_trends()` handler
  - `get_data_statistics()` handler
  - **é¢„ä¼°**ï¼š6 å°æ—¶

- [ ] **Task 2.3**ï¼šAPI æ–‡æ¡£ä¸æµ‹è¯•
  - æ·»åŠ  Utoipa æ–‡æ¡£æ³¨è§£
  - ç¼–å†™å•å…ƒæµ‹è¯•
  - ç¼–å†™é›†æˆæµ‹è¯•
  - **é¢„ä¼°**ï¼š4 å°æ—¶

**Total Phase 2**ï¼š13 å°æ—¶ â†’ **çº¦ 2 å¤©**

---

### Phase 3ï¼šé«˜çº§åŠŸèƒ½ï¼ˆP1ï¼‰

**ç›®æ ‡**ï¼šæ€§èƒ½ä¼˜åŒ–å’Œé«˜çº§ç‰¹æ€§

#### ä»»åŠ¡æ¸…å•

- [ ] **Task 3.1**ï¼šæ•°æ®èšåˆä¼˜åŒ–
  - å®ç°æ¯æ—¥æ±‡æ€»ä»»åŠ¡
  - æ·»åŠ ç¼“å­˜å±‚ï¼ˆå¯é€‰ï¼‰
  - **é¢„ä¼°**ï¼š4 å°æ—¶

- [ ] **Task 3.2**ï¼šTop N æŸ¥è¯¢ä¼˜åŒ–
  - Top è¡¨æŒ‰å¤§å°æŸ¥è¯¢
  - Top è¡¨æŒ‰è®¿é—®é‡æŸ¥è¯¢ï¼ˆéœ€å®¡è®¡æ—¥å¿—ï¼‰
  - **é¢„ä¼°**ï¼š6 å°æ—¶

- [ ] **Task 3.3**ï¼šå®¹é‡é¢„æµ‹ï¼ˆå¯é€‰ï¼‰
  - åŸºäºå†å²æ•°æ®çš„çº¿æ€§å›å½’
  - é¢„æµ‹ç£ç›˜æ»¡æ—¶é—´
  - **é¢„ä¼°**ï¼š8 å°æ—¶

**Total Phase 3**ï¼š18 å°æ—¶ â†’ **çº¦ 2.5 å¤©**

---

### æ€»è®¡

| Phase | ä»»åŠ¡å†…å®¹ | é¢„ä¼°æ—¶é—´ |
|-------|---------|---------|
| Phase 1 | åŸºç¡€æ¶æ„æ­å»º | 4 å¤© |
| Phase 2 | API å¼€å‘ | 2 å¤© |
| Phase 3 | é«˜çº§åŠŸèƒ½ | 2.5 å¤© |
| **Total** | | **8.5 å¤©** |

---

## äº”ã€é£é™©è¯„ä¼°ä¸ç¼“è§£

### 5.1 æŠ€æœ¯é£é™©

#### é£é™© 1ï¼šåå°ä»»åŠ¡å¯èƒ½å½±å“æ€§èƒ½

**æè¿°**ï¼š30 ç§’ä¸€æ¬¡çš„é‡‡é›†å¯èƒ½å¯¹ StarRocks é€ æˆå‹åŠ›

**å½±å“**ï¼šä¸­ç­‰

**ç¼“è§£æªæ–½**ï¼š
- âœ… ä½¿ç”¨å¼‚æ­¥é‡‡é›†ï¼Œä¸é˜»å¡ä¸»çº¿ç¨‹
- âœ… æ·»åŠ é‡‡é›†é—´éš”é…ç½®ï¼ˆå¯è°ƒæ•´ä¸º 60 ç§’ï¼‰
- âœ… å®ç°é‡‡é›†å¤±è´¥é‡è¯•æœºåˆ¶
- âœ… ç›‘æ§é‡‡é›†è€—æ—¶ï¼Œè¶…æ—¶åˆ™å‘Šè­¦

#### é£é™© 2ï¼šSQLite æ•°æ®åº“å¢é•¿è¿‡å¿«

**æè¿°**ï¼š7 å¤© x 2880 æ¬¡é‡‡é›†/å¤© = 20,160 æ¡è®°å½•/é›†ç¾¤

**å½±å“**ï¼šä½

**ç¼“è§£æªæ–½**ï¼š
- âœ… å®ç°è‡ªåŠ¨æ¸…ç†ç­–ç•¥
- âœ… å®šæœŸæ‰§è¡Œ VACUUM
- âœ… ä½¿ç”¨ JSON å­˜å‚¨åŸå§‹æ•°æ®ï¼Œå‡å°‘åˆ—æ•°
- âœ… è€ƒè™‘å¼•å…¥æ•°æ®å‹ç¼©ï¼ˆå¦‚æœéœ€è¦ï¼‰

#### é£é™© 3ï¼šä¸ç°æœ‰ monitor.rs çš„å…¼å®¹æ€§

**æè¿°**ï¼šæ–°æ—§ API å¯èƒ½äº§ç”Ÿæ··æ·†

**å½±å“**ï¼šä½

**ç¼“è§£æªæ–½**ï¼š
- âœ… ä¿ç•™ç°æœ‰ `/api/clusters/:id/metrics/summary` ç«¯ç‚¹ï¼ˆå‘åå…¼å®¹ï¼‰
- âœ… æ–° API ä½¿ç”¨ä¸åŒçš„è·¯å¾„å‰ç¼€ `/api/clusters/:id/overview`
- âœ… åœ¨æ–‡æ¡£ä¸­æ˜ç¡®è¯´æ˜ä¸¤è€…çš„åŒºåˆ«å’Œä½¿ç”¨åœºæ™¯

### 5.2 æ•°æ®ä¸€è‡´æ€§é£é™©

#### é£é™© 4ï¼šé‡‡é›†å»¶è¿Ÿå¯èƒ½å¯¼è‡´æ•°æ®ä¸å‡†ç¡®

**æè¿°**ï¼š30 ç§’é—´éš”å¯èƒ½é”™è¿‡çŸ­æš‚çš„å°–å³°

**å½±å“**ï¼šä¸­ç­‰

**ç¼“è§£æªæ–½**ï¼š
- âœ… å‰ç«¯æ˜¾ç¤ºæ•°æ®é‡‡é›†æ—¶é—´æˆ³
- âœ… æä¾›"åˆ·æ–°"æŒ‰é’®æ‰‹åŠ¨è§¦å‘å®æ—¶æŸ¥è¯¢
- âœ… å¯¹äºå…³é”®æŒ‡æ ‡ï¼Œè€ƒè™‘ä½¿ç”¨æ›´çŸ­çš„é‡‡é›†é—´éš”ï¼ˆå¦‚ 15 ç§’ï¼‰

### 5.3 å¼€å‘é£é™©

#### é£é™© 5ï¼šStarRocks API å¯èƒ½ä¸æ”¯æŒæŸäº›æŒ‡æ ‡

**æè¿°**ï¼šéƒ¨åˆ†æŒ‡æ ‡å¯èƒ½åªèƒ½é€šè¿‡ MySQL åè®®è·å–

**å½±å“**ï¼šä¸­ç­‰

**ç¼“è§£æªæ–½**ï¼š
- âœ… ä¼˜å…ˆéªŒè¯æ‰€æœ‰ API çš„å¯ç”¨æ€§ï¼ˆå‚è€ƒ `CLUSTER_OVERVIEW_DATA_VALIDATION.md`ï¼‰
- âœ… å¯¹äºä¸æ”¯æŒçš„ APIï¼Œä½¿ç”¨ MySQLClient æ›¿ä»£
- âœ… åœ¨è®¾è®¡æ–‡æ¡£ä¸­æ ‡æ³¨æ•°æ®æ¥æºå’Œè·å–æ–¹å¼

---

## å…­ã€æ€»ç»“ä¸å»ºè®®

### 6.1 æ¶æ„è®¾è®¡äº®ç‚¹

1. **æœ€å°ä¾µå…¥æ€§**ï¼šæ–°åŠŸèƒ½å®Œå…¨é€šè¿‡æ‰©å±•å®ç°ï¼Œä¸ä¿®æ”¹ç°æœ‰ä»£ç 
2. **èŒè´£æ¸…æ™°**ï¼šé‡‡é›†ã€å­˜å‚¨ã€æŸ¥è¯¢ã€èšåˆåˆ†ç¦»
3. **æ€§èƒ½ä¼˜åŒ–**ï¼šåå°é‡‡é›† + SQLite ç¼“å­˜ï¼Œå‡å°‘å¯¹ StarRocks çš„å‹åŠ›
4. **å¯æ‰©å±•æ€§**ï¼šæ˜“äºæ·»åŠ æ–°æŒ‡æ ‡å’Œæ–°åŠŸèƒ½
5. **å‘åå…¼å®¹**ï¼šä¿ç•™ç°æœ‰ APIï¼Œä¸å½±å“ç°æœ‰åŠŸèƒ½

### 6.2 å®æ–½å»ºè®®

#### ä¼˜å…ˆçº§æ’åº

1. **P0ï¼ˆMust Haveï¼‰**ï¼šPhase 1 + Phase 2
   - æ ¸å¿ƒé‡‡é›†å’Œå­˜å‚¨èƒ½åŠ›
   - åŸºç¡€ API æ¥å£

2. **P1ï¼ˆShould Haveï¼‰**ï¼šPhase 3
   - æ•°æ®èšåˆä¼˜åŒ–
   - Top N æŸ¥è¯¢

3. **P2ï¼ˆNice to Haveï¼‰**ï¼š
   - å®¹é‡é¢„æµ‹
   - å‘Šè­¦åŠŸèƒ½

#### å¼€å‘é¡ºåº

```
Day 1-2: æ•°æ®åº“ Schema + StarRocksClient æ‰©å±•
Day 3-4: MetricsCollectorService å®ç°
Day 5-6: OverviewService å®ç° + API å¼€å‘
Day 7-8: æµ‹è¯•ã€ä¼˜åŒ–ã€æ–‡æ¡£
Day 9+:   Phase 3 é«˜çº§åŠŸèƒ½
```

### 6.3 ä»£ç è´¨é‡ä¿è¯

- âœ… æ‰€æœ‰æœåŠ¡ç¼–å†™å•å…ƒæµ‹è¯•ï¼ˆè¦†ç›–ç‡ >80%ï¼‰
- âœ… å…³é”® API ç¼–å†™é›†æˆæµ‹è¯•
- âœ… ä½¿ç”¨ `tracing` æ·»åŠ è¯¦ç»†æ—¥å¿—
- âœ… é”™è¯¯å¤„ç†éµå¾ªç°æœ‰ `ApiError` æ¨¡å¼
- âœ… ä»£ç ç¬¦åˆ Rust æœ€ä½³å®è·µï¼ˆClippy æ£€æŸ¥ï¼‰

---

**ç°åœ¨ï¼Œæˆ‘ä»¬æœ‰äº†æ¸…æ™°çš„æ¶æ„é›†æˆæ–¹æ¡ˆï¼Œå¯ä»¥å¼€å§‹å®æ–½äº†ï¼** ğŸš€

